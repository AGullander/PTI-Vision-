# Copy this file to .env and fill in your values

# ============================================
# OpenAI Configuration (cloud-based)
# ============================================
# OpenAI API Key - required for OpenAI vision and text analysis
OPENAI_API_KEY=sk-your-api-key-here

# Optional: Override defaults
# USE_OPENAI_VISION=1
# USE_OPENAI_TEXT=1
# OPENAI_VISION_MODEL=gpt-4o-mini
# OPENAI_TEXT_MODEL=gpt-4.1-mini

# ============================================
# OpenVINO GenAI Configuration (local inference)
# ============================================
# Enable OpenVINO GenAI (set to 1 to use local models)
# USE_OPENVINO=1

# Path to converted OpenVINO VLM model for vision analysis
# Convert first: optimum-cli export openvino --model openbmb/MiniCPM-V-2_6 --weight-format int4 --trust-remote-code MiniCPM_V_2_6_ov
# OPENVINO_VLM_PATH=./models/MiniCPM_V_2_6_ov

# Path to converted OpenVINO LLM model for text reasoning
# Convert first: optimum-cli export openvino --model Qwen/Qwen2.5-3B-Instruct --weight-format int4 --trust-remote-code Qwen2.5-3B-Instruct_ov
# OPENVINO_LLM_PATH=./models/Qwen2.5-3B-Instruct_ov

# Device for OpenVINO inference: CPU, GPU, or NPU
# OPENVINO_DEVICE=CPU

# ============================================
# LLaVA Configuration (local, requires GPU)
# ============================================
# USE_LLAVA=0
# LLAVA_MODEL_ID=llava-hf/llava-1.5-7b-hf

# ============================================
# API and Security
# ============================================
# API key for authentication
# API_KEY=pti_demo_key_2025

# Enable training endpoint (set to 1 to allow)
# ENABLE_TRAIN_YOLO=1
